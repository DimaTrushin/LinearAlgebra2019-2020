\ProvidesFile{lecture11.tex}[Лекция 11]


\subsection{Удобный формализм}

Пусть $V$ -- некоторое векторное пространство над некоторым полем $F$. Возьмем некоторые вектора $v_1,\ldots, v_n\in V$ и набор чисел $x_1,\ldots,x_n\in F$. Тогда можно составить строку из векторов $v_i$ и столбец из чисел $x_i$ и перемножить в следующем порядке
\[
\begin{pmatrix}
{v_1}&{v_2}&{\ldots}&{v_n}
\end{pmatrix}
\begin{pmatrix}
{x_1}\\{x_2}\\{\vdots}\\{x_n}
\end{pmatrix}
=
x_1 v_1 + \ldots + x_n v_n
\]
Таким образом мы можем записывать линейные комбинации с помощью матричных объектов, когда матрицы состоят не только из чисел, но и из векторов.
Если при этом ввести обозначения
\[
v = 
\begin{pmatrix}
{v_1}&{v_2}&{\ldots}&{v_n}
\end{pmatrix}
\quad\text{и}\quad
x = 
\begin{pmatrix}
{x_1}\\{x_2}\\{\vdots}\\{x_n}
\end{pmatrix}
\]
то линейную комбинацию можно записать как $v x$. Если $w\in V$ -- некоторый вектор, то тот факт, что он линейно выражается через $v_i$ тогда записывается так $w = vx$ для некоторого $x\in F^n$. Пусть теперь у нас есть несколько векторов $w_1,\ldots, w_m\in V$ и каждый из них выражается через вектора $v_1,\ldots, v_n$, тогда
\[
w_1 = 
\begin{pmatrix}
{v_1}&{v_2}&{\ldots}&{v_n}
\end{pmatrix}
A_1,
\ldots,
w_m = 
\begin{pmatrix}
{v_1}&{v_2}&{\ldots}&{v_n}
\end{pmatrix}
A_m
\]
где $A_i\in F^n$. Тогда составим из $A_i$ матрицу $A\in \operatorname{M}_{n\,m}(F)$ и получим запись
\[
\begin{pmatrix}
{w_1}&{w_2}&{\ldots}&{w_m}
\end{pmatrix}
=
\begin{pmatrix}
{v_1}&{v_2}&{\ldots}&{v_n}
\end{pmatrix}
A
\]

\subsection{Размерность}

Наша задача сейчас показать, что в векторном пространстве любые два базиса имеют одинаковое количество элементов. Однако, обсуждать как сравнивать бесконечные множества между собой я не очень хочу, потому мы с этого момента ограничимся случаями конечных базисов. Для начала нам надо показать, что если векторное пространство имеет хотя бы один конечный базис, то все его базисы конечны и имеют одинаковое количество элементов.

\begin{claim}
Пусть $V$ -- некоторое векторное пространство над полем $F$ и пусть $\{e_1,\ldots,e_n\}\subseteq V$ -- базис $V$. Тогда если $E\subseteq V$ -- некоторый базис $V$, то $|E| = n$.
\end{claim}
\begin{proof}
Нам достаточно показать, что $|E|\leqslant n$. Тогда базис $E$ становится конечным и мы можем поменять местами два базиса и применить это же утверждение для доказательства обратного неравенства.

Предположим, что это не верно, тогда в $E$ есть хотя бы $n+1$ элемент $v_1,\ldots, v_{n+1}$. Так как $e_1,\ldots, e_n$ -- базис, то каждый $v_i$ линейно выражается через этот базис. Значит можно найти матрицу $A\in \operatorname{M}_{n\,n+1}(F)$ такую, что
\[
\begin{pmatrix}
{v_1}&{v_2}&{\ldots}&{v_{n+1}}
\end{pmatrix}
=
\begin{pmatrix}
{e_1}&{e_2}&{\ldots}&{e_n}
\end{pmatrix}
A
\]
Рассмотрим систему $Ax = 0$, где $x\in F^{n+1}$. В этой системе количество столбцов больше, чем количество строк. Значит обязательно существует ненулевое решение $x\in F^{n+1}$. Тогда умножим на него предыдущее равенство слева, получим
\[
\begin{pmatrix}
{v_1}&{v_2}&{\ldots}&{v_{n+1}}
\end{pmatrix}x
=
\begin{pmatrix}
{e_1}&{e_2}&{\ldots}&{e_n}
\end{pmatrix}
Ax=
0
\]
То есть мы нашли нетривиальную линейную комбинацию векторов $v_1,\ldots, v_{n+1}$. Но по определению $E$ в нем не должно быть линейно зависимых векторов, противоречие.
\end{proof}

Пусть $V$ -- векторное пространство над полем $F$, тогда размерностью $V$ называется число элементов в любом из его базисов.\footnote{Корректность этого определения следует из предыдущей леммы в случае существования хотя бы одного конечного базиса. Однако, если бы мы были знакомы с теорией мощности для произвольных множеств, то мы бы показали, что количество элементов в базис не зависит от базиса всегда. Потому можно говорить о размерности даже для бесконечно мерных пространств. Например, размерность многочленов $F[x]$ счетная, а для бесконечного множества $X$ размерность пространства $F^X$ совпадает с $|F^X|$, то есть она зависит от мощности поля.} Размерность $V$ будем обозначать через $\dim V$ или $\dim_F V$, если надо подчеркнуть, какое поле $F$ имеется в виду.

\begin{claim}
Пусть $U\subseteq V$ -- подпространство в векторном пространстве над полем $F$. Тогда
\begin{enumerate}
\item $\dim U \leqslant \dim V$.
\item $\dim U = \dim V$ тогда и только тогда, когда $U = V$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) В начале сделаем замечание. Пусть $E\subseteq V$ -- какое-то линейно независимое подмножество $V$. Так как базис -- это максимальное линейно независимое подмножество, то $|E|\leqslant \dim V$.

Пусть $E\subseteq U$ -- базис $U$. Тогда $E$ -- линейно независимое подмножество $U$, а значит и $V$. Но тогда из замечания выше $|E|\leqslant \dim V$. А по определению $\dim U = |E|$.

 (2) Теперь сделаем еще одно замечание. Пусть $E\subseteq V$ -- некоторое линейно независимое подмножество $V$. Как понять, что оно максимальное? Достаточно, проверить, что в нем $\dim V$ элементов. Действительно, если бы при этом оно было не максимальным, то в максимальном было бы больше $\dim V$ элементов, что противоречит определению размерности.
 
Теперь пусть $E\subseteq U$ -- базис $U$ и пусть $\dim U = \dim V$. Мы хотим показать, что $ U = V$. Тогда $E$ -- это линейно независимое подмножество в $V$ и в нем $|E| = \dim U = \dim V$ элементов. Но тогда по замечанию выше оно является базисом в $V$. Так как $E$ -- базис в $U$, то $U = \langle E \rangle$, а так как $E$ -- базис в $V$, то $V = \langle E \rangle$, то есть $U= V$. Утверждение в обратную сторону очевидно.
\end{proof}

\subsection{Подпространства в $F^n$}\label{section::Subspaces}

Давайте посмотрим как можно задавать подпространства в $F^n$. Существует два способа
\vspace{3pt}

\begin{tabular}{c|c}
{\bf Явный}&{\bf Неявный}\\
\hline
{Если $v_1,\ldots,v_k\in V$, тогда $U = \langle v_1,\ldots, v_k \rangle$}&{Если $A\in \operatorname{M}_{m\,n}(F)$, тогда $U = \{y\in F^n \mid Ay = 0\}$}\\
\end{tabular}
\vspace{3pt}

По-хорошему, хочется научиться пересчитывать векторное пространство заданное в одной из этих форм в другую. Мы разберем пока только одну из этих задач. А именно, пусть подпространство задано неявно в виде системы, то как найти его базис? 

Если подпространство $U\subseteq F^n$ задано в виде $U = \{y\in F^n\mid Ay = 0\}$ для некоторой матрицы $A\in\operatorname{M}_{m\,n}(F)$, то любой базис пространства $U$ будем называть фундаментальной системой решений (ФСР). Ниже мы разберем задачу построения какого-нибудь ФСР для однородной системы линейных уравнений.

\paragraph{Нахождение ФСР однородной СЛУ}

В начале мы приведем алгоритм находящий ФСР, а потом объясним почему он работает.

\paragraph{Дано} Система однородных линейных уравнений $Ax = 0$, где $A\in \operatorname{M}_{m\,n}(F)$ и $x\in F^n$.

\paragraph{Задача} Найти ФСР системы $Ax = 0$.

\paragraph{Алгоритм}
\begin{enumerate}
\item Привести матрицу $A$ элементарными преобразованиями строк к улучшенному ступенчатому виду. Например
\[
A' = 
\begin{pmatrix}
{1}&{0}&{a_{31}}&{0}&{a_{51}}\\
{0}&{1}&{a_{32}}&{0}&{a_{52}}\\
{0}&{0}&{0}&{1}&{a_{53}}\\
\end{pmatrix}
\]

\item Пусть $k_1,\ldots,k_r$ -- позиции свободных переменных. Если положить одну из этих переменных равной $1$, а все остальные нулями, то существует единственное решение, которое мы обозначим через $u_i$ (всего $r$ штук). Например, для матрицы $A'$ выше свободные переменные имеют номера $3$ и $5$. Тогда вектора (записанные в строку)
\[
u_1 = 
\begin{pmatrix}
{-a_{31}}&{-a_{32}}&{1}&{0}&{0}
\end{pmatrix},\,
u_2 = 
\begin{pmatrix}
{-a_{51}}&{-a_{52}}&{0}&{-a_{53}}&{1}
\end{pmatrix}
\]
являются ФСР.
\end{enumerate}

\begin{proof}[Доказательство корректности алгоритма поиска ФСР]

Пусть в общем виде, ступенчатый вид матрицы $A$ выглядит так
\[
\begin{pmatrix}
{1}&{*}&{0}&{*}&{0}&{*}&{*}&{0}&{*}\\
{}&{}&{1}&{*}&{0}&{*}&{*}&{0}&{*}\\
{}&{}&{}&{}&{1}&{*}&{*}&{0}&{*}\\
{}&{}&{}&{}&{}&{}&{}&{1}&{*}\\
\end{pmatrix}
\]
Тогда построенные вектора имеют вид
\[
\begin{matrix}
{}&{}&{k_1}&{}&{k_2}&{}&{\ldots}&{\ldots}&{}&{k_r}\\
{u_1 }&{(*}&{1}&{0}&{0}&{0}&{0}&{0}&{0}&{0)}\\
{u_2}&{(*}&{0}&{*}&{1}&{0}&{0}&{0}&{0}&{0)}\\
{\vdots}&{(*}&{0}&{*}&{0}&{*}&{1}&{0}&{0}&{0)}\\
{\vdots}&{(*}&{0}&{*}&{0}&{*}&{0}&{1}&{0}&{0)}\\
{u_r}&{(*}&{0}&{*}&{0}&{*}&{0}&{0}&{*}&{1)}\\
\end{matrix}
\]
В начале проверим, что $u_i$ линейно независимы. Действительно, тогда линейная комбинация $\alpha_1 u_1 +\ldots + \alpha_r u_r$ имеет вид
\[
\begin{pmatrix}
{*}&{\alpha_1}&{*}&{\alpha_2}&{*}&{\ldots}&{\ldots}&{*}&{\alpha_r}\\
\end{pmatrix}
\]
Если эта линейная комбинация равна нулю, то значит и все $\alpha_i$ равны нулю.

Теперь пусть $v$ -- произвольное решение системы $Ax = 0$. Посмотрим на его координаты в свободных позициях
\[
\begin{pmatrix}
{*}&{v_1}&{*}&{v_2}&{*}&{\ldots}&{\ldots}&{*}&{v_r}\\
\end{pmatrix}
\]
Теперь рассмотрим вектор $w = v - v_1 u_1 - \ldots - v_r u_r$. С одной стороны это решение системы $Ax = 0$. С другой стороны у этого решения все свободные переменные равны нулю. А значит автоматически и все главные переменные равны нулю, что означает, что $w  = 0$. То есть $v = v_1 u_1 + \ldots + v_r u_r$, что и требовалось.
\end{proof}

\subsection{Конкретные векторные пространства}\label{subsection::FnSpace}

Пусть $V$ -- векторное пространство над некоторым полем $F$. Вообще говоря, в этом случае элементы $V$ могут быть чем угодно (функции, вектор-столбцы, матрицы, отображения и т.д.), но если в нем можно выбрать конечный базис, то оно автоматически превратится в пространство $F^n$. Сейчас я хочу обсудить все этапы этого магического превращения.

Пусть $e_1,\ldots,e_n\in V$ -- некоторый базис пространства $V$. Тогда можно рассмотреть отображение 
\begin{align*}
F^n &\to V\\
x &\mapsto ex
\end{align*}
где $e=(e_1,\ldots,e_n)$, $x\in F^n$. Так как $e$ порождает $V$, то это отображение сюръективно. С другой стороны из линейной независимости следует инъективность: если $ex = ey$ для $x,y\in F^n$, то $e (x - y) = 0$, а значит $ x - y = 0$. Таким образом мы получаем, что каждый вектор-столбец длины $n$ однозначно соответствует некоторому вектору из $V$. Кроме того, если присмотреться внимательно, то мы увидим, что сложение столбцов соответствует сложению векторов и то же самое верно для умножения на скаляр. Таким образом, мы видим, что между этими пространствами нет никакой разницы. Изучать одно из них -- это все равно, что изучать другое. По-другому, можно думать еще так: если вам дали произвольное конечномерное пространство, то всегда можно считать, что это $F^n$ (для этого нужно всего лишь выбрать базис).

\paragraph{Координаты} Если вектор $v\in V$ разложен по некоторому базису $e = (e_1,\ldots,e_n)$ пространства $V$, то есть представлен в виде $v = ex$, где $x\in F^n$, то столбец $x = (x_1,\ldots,x_n)$ называют координатами вектора $v$ в базисе $e_1,\ldots, e_n$. 

\paragraph{Смена базиса}

Так как базис в пространстве выбирается не единственным образом, то в конструкции выше у нас есть некоторая свобода. Давайте проследим, что и как меняется при замене одного базиса другим.

\begin{claim}\label{claim::BasisClassification}
Пусть $V$ -- некоторое векторное пространство над полем $F$ и пусть $e_1,\ldots, e_n\in V$ -- какой-нибудь базис этого пространства. Тогда
\begin{enumerate}
\item Для любой обратимой матрицы $C\in \operatorname{M}_{n}(F)$ набор векторов $(e_1,\ldots,e_n)C$ тоже является базисом.

\item Если $f_1,\ldots,f_n\in V$ -- любой другой базис $V$, то найдется единственная обратимая матрица $C\in\operatorname{M}_n(F)$ такая, что $(f_1,\ldots,f_n) = (e_1,\ldots,e_n)C$.
\end{enumerate}
\end{claim}
\begin{proof}
(1) Заметим, что набор $(e_1,\ldots,e_n)C$ является линейно независимым и состоит из $n = \dim V$ элементов, а значит автоматом максимальный линейно независимый набор. Для проверки линейной независимости рассмотрим линейную комбинацию $(e_1,\ldots,e_n)Cx = 0$, где $x\in F^n$. Тогда $Cx = 0$ так как $e_i$ базис. А следовательно $x = 0$, так как $C$ обратима.

(2) Так как $e_i$ -- базис, то любой вектор однозначно раскладывается по этому базису, например, каждый $f_i$ имеет представление $f_i = (e_1,\ldots, e_n) C_i$, где $C_i\in F^n$. Тогда все эти равенства вместе можно записать так $(f_1,\ldots,f_n) = (e_1,\ldots,e_n) C$, где $C = (C_1|\ldots|C_n)\in \operatorname{M}_n (F)$ -- квадратная матрица составленная из столбцов $C_i$. То есть такая матрица найдется, а ее единственность следует из того, что любой вектор однозначно раскладывается по базису.

Теперь осталось доказать обратимость матрицы $C$. Применив, то же самое рассуждение но для базисов в обратном порядке, мы найдем матрицу $B\in \operatorname{M}_n(F)$ такую, что $(e_1,\ldots,e_n) = (f_1,\ldots,f_n) B$. Тогда получаем 
\[
(e_1,\ldots,e_n) = (f_1,\ldots,f_n)B = (e_1,\ldots,e_n)CB
\]
А значит $(e_1,\ldots, e_n)(E - CB) = 0$. Из линейной независимости базиса следует, что $E = CB$. Аналогично доказывается $BC = E$, то есть $B$ является обратной к $C$, что и требовалось.
\end{proof}


Если $e_1,\ldots,e_n$ и $f_1,\ldots,f_n$ -- два базиса пространства $V$, то матрица $C\in \operatorname{M}_n(F)$ такая, что $(f_1,\ldots, f_n) = (e_1,\ldots,e_n)C$ называется матрицей перехода от базиса $e_i$ к базису $f_i$. Таким образом у нас есть, вообще говоря бесконечный, граф с вершинами пронумерованными базисами пространства $V$, а ребра соответствуют матрицам перехода $C$ от базиса $e_i$ к базису $f_i$, если $(f_1,\ldots,f_n) = (e_1,\ldots,e_n)C$. Предыдущее утверждение говорит, что этот граф связный и между любыми двумя вершинами есть ровно одно ребро.\footnote{Кстати между вершиной и ей самой тоже есть ребро-петля, соответствующая единичной матрице.}

\paragraph{Смена координат}

Пусть теперь у нас $v\in V$ -- некоторый вектор. Тогда мы его можем разложить по одному базису $v = ex$ с координатами $x\in F^n$ и по другому базису $v = f y$ с координатами $y \in F^n$. Пусть $C$ -- матрица перехода от базиса $e$ к базису $f$, то есть $f = e C$. Тогда координаты $x$ в старом базисе $e$ связаны с новыми координатами в базисе $f$ следующим образом: $x = Cy$. Действительно, с одной стороны $v = ex$, а с другой $v = f y = eC y$. Но так как разложение по базису однозначно, получаем, что $x = Cy$. Запоминать это правило надо так: если от базиса $e$ к базису $f$ мы перешли с помощью умножения справа на матрицу $C$, то на координатах у нас отображение в обратную сторону с помощью умножения на матрицу $C$ слева (то есть тоже с другой стороны). Еще полезно держать перед глазами вот эту таблицу.
\begin{center}
\begin{tabular}{c|c}
{базис}&{новый $\stackrel{\cdot C}{\longleftarrow}$ старый}\\
\hline
{координаты}&{новые $\stackrel{C\cdot}{\longrightarrow}$ старые}\\
\end{tabular}
\end{center}

\subsection{Ранг}

В начале обсудим общее понятие ранга системы векторов в произвольном векторном пространстве.

\begin{claim}
Пусть $V$ -- некоторое векторное пространство над полем $F$. Пусть $S = (v_1,\ldots,v_k) $ -- система векторов из $V$.\footnote{Формально $S\in V^k$, то есть это упорядоченный набор векторов, где векторы могут повторяться.} Пусть $S'\subseteq S$ -- максимальный линейно независимый поднабор в $S$.\footnote{Это означает, что элементы $S'$ не повторяются, полученное множество является линейно независимым и к набору $S'$ нельзя добавить ни один вектор из $S$, чтобы получился линейно независимый набор.}\footnote{Формально мы разбирались лишь со случаем множества векторов, но я не хочу разводить формальный геморрой на ровном месте и уверен, что каждый из вас сможет без труда распространить все необходимые определения и факты на наборы вместо множеств.} Тогда $|S'| = \dim_F \langle S\rangle$.
\end{claim}
\begin{proof}
Рассмотрим $\langle S \rangle\subseteq V$. Если мы покажем, что $\langle S' \rangle = \langle S \rangle$, то по определению $S'$ будет базисом $\langle S\rangle$, как порождающее и линейно независимое. Для этого нам достаточно показать, что любой вектор из $S\setminus S'$ выражается через векторы из $S'$. Действительно, возьмем такой вектор $v\in S\setminus S'$, тогда набор составленный из $S'$ и $v$ уже будет линейно зависимым, то есть есть линейная комбинация вида $\sum_i\alpha_i v_i' + \alpha v = 0$, где  $v_i'\in S'$ и $\alpha_i,\alpha\in F$. Коэффициент $\alpha\neq 0$ иначе это означало бы линейную зависимость $S'$. А значит можно выразить $v$ через $v_i'$ перенеся $\alpha v $ направо и разделив на $-\alpha$.
\end{proof}

В частности это утверждение делает корректным следующее.

\begin{definition}
Пусть $V$ -- векторное пространство и $S = (v_1,\ldots,v_k)$ -- набор векторов из $V$. Тогда рангом $S$ называется размер максимального линейно независимого поднабора и обозначается $\rk S$.
\end{definition}

Кроме корректности, утверждение выше говорит, что $\rk (v_1,\ldots,v_k) = \dim_F \langle v_1, \ldots,v_k\rangle$. К рангу надо относиться так -- это дискретный аналог размерности. Векторное пространство -- объект большой и сложный, базисов в нем много, потому его недостаток -- с ним сложно работать. Конечный набор векторов -- объект простой и понятный, с ним намного проще работать, чем целиком со всем пространством. Однако, главный недостаток -- он недостаточно гибкий по сравнению с векторным пространством, если мы чуть-чуть поменяем вектора (например, прибавим один к другому) мы уже изменим набор, но не изменим векторного пространства. Как обычно, каким-то из этих понятий удобно пользоваться в одних ситуациях, а в каких-то ситуациях намного лучше подходит другое.


\subsection{Матричный ранг}

Пусть $A\in \operatorname{M}_{m\,n}(F)$ -- некоторая матрица с коэффициентами в поле $F$.

\begin{definition}
Пусть $A_1,\ldots,A_n\in F^m$ -- столбцы матрицы $A$, то есть $A = (A_1|\ldots|A_n)$. Тогда столбцовым рангом матрицы $A$ называется ранг системы $(A_1,\ldots,A_n)$, то есть $\rk_{\text{столб}} A = \rk (A_1,\ldots,A_n)$.
\end{definition}

\begin{definition}
Пусть $A_1,\ldots,A_m\in F^n$ -- строки матрицы $A$, то есть $A^t = (A_1|\ldots|A_m)$. Тогда строковым рангом матрицы $A$ называется ранг системы $(A_1,\ldots,A_m)$, то есть $\rk_{\text{стр}} A = \rk (A_1,\ldots,A_m)$.
\end{definition}


\begin{definition}
Факториальным рангом матрицы $A$ называется следующее число
\[
\min \{k \mid A = BC,\text{ где }B\in \operatorname{M}_{m\,k}(F),\,C\in\operatorname{M}_{k\,n}(F)\}
\]
то есть это минимальное число $k$ такое, что матрица $A$ представима в виде произведения матриц $BC$, где общая размерность для $B$ и $C$, по которой они перемножаются, есть $k$.
\end{definition}

\begin{definition}
Тензорным рангом матрицы $A$ называется следующее число
\[
\min\{k \mid A = x_1y_1^t+\ldots + x_k y_k^t,\text{ где }x_i\in F^m,\, y_i\in F^n\}
\]
то есть это минимальное число $k$ такое, что матрица $A$ представима в виде суммы $k$ <<тощих>> матриц вида $xy^t$, где $x\in F^m$ и $y\in F^n$.
\end{definition}


Перед следующим определением нам нужна некоторая подготовка. Зафиксируем некоторый набор индексов для строк: $1\leqslant i_1<\ldots<i_k\leqslant m$, а так же некоторый набор индексов для столбцов в том же количестве $1\leqslant j_1<\ldots<j_k\leqslant n$. Тогда обозначим через $A_{i_1,\ldots,i_k}^{j_1,\ldots,j_k}\in \operatorname{M}_k(F)$ подматрицу образованную пересечением данных строк и столбцов. То есть формально ее элементы это $\bar a_{st} = a_{i_s j_t}$. Такую матрицу будем называть квадратной подматрицей матрицы $A$ размера $k$.

\begin{definition}
Минорным рангом матрицы $A$ называется размер максимальной невырожденной квадратной подматрицы, то есть минорный ранг $A$ -- это такое $k$, что существует невырожденная подматрица $A_{i_1,\ldots,i_k}^{j_1,\ldots,j_k}\in \operatorname{M}_k(F)$ такая, что любая квадратная подматрица ее содержащая уже вырождена.\footnote{Обратите внимание, что нужно еще доказывать корректность этого определения, а именно, что число $k$ не зависит от выбора максимальной невырожденной подматрицы. Это вообще говоря не очевидно.}
\end{definition}

В начале сделаем очень полезное замечание.

\begin{claim}\label{claim::rkFactorTensor}
Для любой матрицы $A\in \operatorname{M}_{m\,n}(F)$ ее факториальный ранг равен тензорному.
\end{claim}
\begin{proof}
Пусть $B\in \operatorname{M}_{m\,k}(F)$ и  $\,C\in\operatorname{M}_{k\,n}(F)$ -- такие матрицы, что $A = BC$. Пусть $B = (B_1|\ldots|B_k)$ и $C^t = (C_1|\ldots|C_k)$. Тогда по блочным формулам $BC = B_1 C_1^t + \ldots + B_kC_k^t$. Это доказывает, что тензорный ранг $A$ не превосходит факториального. Наоборот, если задано разложение $BC = B_1 C_1^t + \ldots + B_kC_k^t$, то определим матрицы $B = (B_1|\ldots|B_k)$ и $C^t = (C_1|\ldots|C_k)$ и получим, что $A = BC$. Это доказывает оценку рангов в другую сторону.
\end{proof}


Наша цель в этом разделе очень проста -- показать, что все пять определений  ранга совпадают между собой. Начнем со следующего.

\begin{claim}\label{claim::rkInvariance}
Пусть $A\in\operatorname{M}_{m\,n}(F)$ -- произвольная матрица, тогда столбцовый, строковый, факториальный и тензорный ранги не меняются при домножении $A$ слева или справа на невырожденную матрицу.
\end{claim}
\begin{proof}
(1) Столбцовый ранг. Пусть $A = (A_1|\ldots|A_n)$, где $A_i\in F^m$ и пусть $D\in \operatorname{M}_n(F)$ -- обратимая матрица. Тогда $\langle (A_1,\ldots,A_n)\rangle = \langle (A_1, \ldots, A_n) D\rangle$ (включение $\supseteq$ очевидно, а обратное следует из обратимости $D$), а значит
\[
\rk_{\text{столб}}(A) = \dim\langle (A_1,\ldots,A_n)\rangle = \dim\langle (A_1, \ldots, A_n) D\rangle = \rk_{\text{столб}}(AD)
\]

Пусть теперь $C\in \operatorname{M}_m(F)$ -- обратимая матрица. Тогда система $Ax = 0$ эквивалентна системе $CAx = 0$. Если какая-то линейная комбинация $x_1 A_1 + \ldots + x_n A_n = 0$, то это значит, что $Ax = 0$, т.е. $x$ является решением системы $Ax = 0$, а значит и решением системы $CAx = 0$, то есть столбцы матрицы $CA$ удовлетворяют той же самой линейной комбинации, что и столбцы матрицы $A$. Это значит, что если какое-то множество столбцов в $A$ было линейно независимо, то множество столбцов с теми же самыми номерами в $CA$ тоже линейно независимы. И если какой-то столбец из $A$ выражался через другие, то и в $CA$ столбец с тем же номером будет выражаться с помощью той же самой линейной комбинации через другие. Потому максимальная линейно независимая система в $A$ переходит в максимальную линейно независимую систему в $CA$.\footnote{Еще один способ думать про это доказательство такое. Можно считать, что столбцы матрицы $A$ -- это векторы в $F^m$, а умножение на $C$ слева -- это замена координат в пространстве $F^n$, то есть мы ничего не делаем с нашими векторами, но меняем стандартный базис в $F^n$ на какой-то другой. Потому столбцы $CA$ -- это координаты тех же самых векторов, что и исходные, только записанные в другом базисе. А раз это те же самые векторы, то у нас ничего не поменялось, кроме их << внешнего вида>>.} Последнее по определению означает $\rk_{\text{столб}} A = \rk_{\text{столб}}(CA)$.


(2) Строковый ранг. Так как $\rk_{\text{столб}}A = \rk_{\text{стр}}(A^t)$, то этот случай следует из предыдущего.

(3) Факториальный ранг. Пусть  $\rk_{\text{ф}}A = k$ и пусть $A = BC$ -- разложение на котором достигается ранг $A$. Тогда $AD = B(CD)$ -- некоторое разложение для $AD$ с числом $k$, а значит по определению $\rk_{\text{ф}}(AD) \leqslant \rk_{\text{ф}} A$. Обратное неравенство следует из обратимости $D$, т.е. $AD = (AD)D^{-1}$. Домножение на матрицу слева делается аналогично.

(4) В силу замечания выше (утверждение~\ref{claim::rkFactorTensor}) тензорный ранг и факториальный -- это одно и то же, потому этот пункт следует из предыдущего.
\end{proof}

\begin{claim}
Пусть $A\in \operatorname{M}_{m\,n}(F)$, тогда столбцовый, строковый, факториальный и тензорный ранги для нее совпадают.
\end{claim}
\begin{proof}
Домножив матрицу $A$ слева и справа на обратимую, мы можем считать, что она имеет следующий вид $\left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right)$. Из утверждения~\ref{claim::rkInvariance} следует, что достаточно доказать утверждение для последней матрицы.

Давайте посчитаем $\rk_{\text{столб}}\left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right)  = r$, где $r$ -- размер единичной матрицы $E$. Аналогично $\rk_{\text{стр}}\left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right) = r$. Более того, для минорного ранга $\rk_{\text{м}}\left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right) = r$, так как матрица $E$ является невырожденной матрицей размера $r$, а все большие подматрицы вырождены, потому что имеют нулевую строку или столбец. То есть эти три ранга равны между собой.


Теперь осталось доказать, что факториальный ранг совпадает со столбцовым (строковым) рангом. Если $A = BC = (B_1|\ldots|B_k)C$ -- равенство, на котором достигается факториальный ранг. Тогда столбцы матрицы $A$ выражаются через столбцы матрицы $B$, то есть $\langle A_1,\ldots,A_m\rangle \subseteq \langle B_1,\ldots,B_k\rangle$, а значит 
\[
\rk_{\text{столб}}A = \dim \langle A_1,\ldots,A_m\rangle \leqslant \dim \langle B_1,\ldots,B_k\rangle\leqslant k=\rk_{\text{ф}}A
\]

С другой стороны
\[
\begin{pmatrix}
{E}&{0}\\
{0}&{0}
\end{pmatrix}
=
\begin{pmatrix}
{E}&{0}\\
\end{pmatrix}
\begin{pmatrix}
{E}\\
{0}
\end{pmatrix}
\]
где общая размерность матриц справа равна строковому рангу, а значит факториальный ранг не превосходит этой размерности. Что дает обратное неравенство.
\end{proof}
