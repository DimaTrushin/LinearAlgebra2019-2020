\ProvidesFile{lecture33.tex}[Лекция 33]

\subsection{Классификация самосопряженных операторов}

\begin{claim}\label{claim::SelfAdjHDiag}
Пусть $V$ -- эрмитово пространство и $\phi\colon V\to V$ -- некоторый оператор. Тогда оператор $\phi$ самосопряжен тогда и только тогда, когда
\begin{enumerate}
\item $\phi$ диагонализуем в ортонормированном базисе.
\item $\spec_\mathbb C\phi\subseteq \mathbb R$.
\end{enumerate}
\end{claim}
\begin{proof}
($\Leftarrow$). Если в некотором ортонормированном базисе $\phi$ задан диагональной матрицей $A$ с вещественными числами на диагонали, то $\bar A^t = A^t = A$. А значит $\phi$ самосопряжен.

($\Rightarrow$). Утверждение~\ref{claim::SelfAdjBasicProp} пункт~(1) уже влечет, что спектр $\phi$ целиком состоит из вещественных чисел. Нам лишь надо показать, что оператор диагонализуется. Так как спектр не пуст, то существует собственный вектор $v\in V$ с вещественным собственным значением $\lambda$. Тогда $V = \langle v\rangle \oplus \langle v\rangle^\bot$. Так как $\langle v \rangle$ является $\phi$ инвариантным, то $U = \langle v\rangle^\bot$ является $\phi$ инвариантным (утверждение~\ref{claim::SelfAdjBasicProp} пункт~(3)). А значит индукцией по размерности пространства, мы находим ортонормированный базис $e_2,\ldots,e_n$ в пространстве $U$, в котором диагонализуется оператор $\phi|_U$. Если мы выберем $e_1 = v / |v|$, то получим искомый базис $e_1,e_2,\ldots,e_n$.
\end{proof}

\begin{claim}\label{claim::SelfAdjHExists}
Пусть $V$ -- комплексное векторное пространство и $\phi\colon V\to V$ -- некоторый оператор. Тогда существует скалярное произведение на $V$ такое, что $\phi$ становится самосопряженным оператором тогда и только тогда, когда
\begin{enumerate}
\item $\phi$ диагонализуем.
\item $\spec_\mathbb C\phi\subseteq \mathbb R$.
\end{enumerate}
\end{claim}
\begin{proof}
($\Rightarrow$). Если существует такое скалярное произведение, то все следует из предыдущего утверждения~\ref{claim::SelfAdjHDiag}.

($\Leftarrow$). Пусть теперь $e_1,\ldots,e_n$ -- базис в котором $\phi$ диагонализуем. Тогда зададим скалярное произведение так, чтобы этот базис был ортонормированным. В этом случае выполнена пара условий из утверждения~\ref{claim::SelfAdjHDiag} и мы получаем, что $\phi$ самосопряжен относительно построенного скалярного произведения.
\end{proof}


\begin{claim}\label{claim::SelfAdjEDiag}
Пусть $V$ -- евклидово пространство и $\phi\colon V\to V$ -- некоторый оператор. Тогда $\phi$ самосопряжен тогда и только тогда, когда $\phi$ диагонализуем в ортонормированном базисе.
\end{claim}
\begin{proof}
Доказательство этого утверждения один в один повторяет слова доказательства в комплексном случае (утверждение~\ref{claim::SelfAdjHDiag}). Единственное обратите внимание, что тут мы просто пользуемся тем, что по утверждению~\ref{claim::SelfAdjBasicProp} пункт~(1), спектр самосопряженного оператора не пуст.
\end{proof}

\begin{claim}
Пусть $V$ -- некоторое вещественное пространство и $\phi\colon V\to V$ -- некоторый оператор. Тогда существует скалярное произведение такое, что $\phi$ самосопряжен, тогда и только тогда, когда $\phi$ диагонализуем.
\end{claim}
\begin{proof}
Доказательство слово в слово повторяет комплексный случай (утверждение~\ref{claim::SelfAdjHExists}).
\end{proof}

\subsection{Билинейные формы и операторы}

В евклидовом пространстве есть тесная связь между линейными операторами и билинейными формами. Аналогичная связь есть в эрмитовых пространствах, но уже между операторами и полуторалинейными формами. Этот механизм позволяет связать характеристики оператора с характеристиками билинейной (или полуторалинейной) формы. Я собираюсь обсудить эту связь.


Пусть $V$ -- евклидово или эрмитово пространство и пусть задан линейный оператор $\phi\colon V\to V$. Тогда он определяет билинейную (полуторалинейную) форму на $V$ по правилу $\beta_\phi(v, u) = (v, \phi u)$. Таким образом получается отображение $\Hom_\mathbb R(V, V)\to \Bil(V)$ в евклидовом случае и $\Hom_\mathbb C(V, V)\to \Bil_{1\frac{1}{2}}(V)$ в эрмитовом. Давайте теперь посмотрим как это отображение выглядит в некотором базисе. 

Я для определенности разберу комплексный случай, вещественный делается аналогично. Пусть $e_1,\ldots,e_n$ -- ортонормированный базис $V$, тогда $V$ превращается в $\mathbb C^n$, скалярное произведение превращается в стандартное $(x, y) = \bar x^t y$ и оператор задается $\phi x = Ax$ для некоторой $A\in \operatorname{M}_n(\mathbb C)$. В этом случае билинейная форма $\beta_\phi$ имеет вид $\beta_\phi(x,y) = \bar x^t A y$, то есть задается той же самой матрицей. Таким образом мы видим, что в случае выбора ортонормированного базиса, отображение из операторов в билинейные (полуторалинейные) формы превращается в тождественное отображение на матрицах.\footnote{Важно иметь в виду, что при выборе не ортонормированного базиса, отображение будет иметь вид $A\mapsto G A$, где $G$ -- матрица скалярного произведения в выбранном базисе.} В частности, построенное отображение из операторов в билинейные (полуторалинейные) формы является биекцией и даже изоморфизмом векторных пространств. Что по простому означает следующее: для любой билинейной (полуторалинейной) формы $\beta$ существует единственный линейный оператор $\phi\colon V\to V$ такой, что $\beta(v,u) = (v, \phi u)$.

Обратите внимание, что в вещественном случае оператор $\phi\colon V\to V$ самосопряжен тогда и только тогда, когда $\beta_\phi$ симметрична. В комплексном случае $\phi$ самосопряжен тогда и только тогда, когда $\beta_\phi$ эрмитова. Действительно, давайте проверим это для комплексного случая. Если выбрать ортонормированный базис и оператор $\phi$ превращается в $\phi x = A x$, то условие самосопряженности оператора -- это условие $\bar A^t = A$. При этом полуторалинейная функция будет иметь вид $\beta_\phi(x, y) = \bar x^t A y$ и условие ее эрмитовости -- это опять же условие $\bar A^t = A$. Вот и все.\footnote{Это условие можно было бы проверять без базиса. По определению $\beta_\phi(v, u) = (v, \phi u)$, кроме того $\overline{\beta_\phi(u, v)} = \overline{(u, \phi v)} = (\phi v, u) = (v, \phi^* u)$. Таким образом равенство этих двух выражений совпадает с определением эрмитовости $\beta_\phi$ и самосопряженности $\phi$.} У этого наблюдения про формы и операторы есть два полезных следствия.

\begin{claim}\label{claim::BilinOrthoDiag}
Пусть $V$ -- евклидово или эрмитово пространство и $\beta$ -- симметричная билинейная (или эрмитова) форма. Тогда существует ортонормированный базис $e_1,\ldots,e_n$, в котором $\beta$ задается диагональной матрицей.
\end{claim}
\begin{proof}
Пусть $\phi\colon V\to V$ такой оператор, что $\beta(v, u) = (v, \phi u)$. Так как $\beta$ симметрична (эрмитова) оператор $\phi$ является самосопряженным. Пусть $e_1,\ldots,e_n$ -- ортонормированный базис, в котором $\phi$ диагонализуется. Тогда он задан в этом базисе диагональной матрицей $A = \diag(\lambda_1,\ldots,\lambda_n)$. Так как базис $e_1,\ldots,e_n$ ортонормированный, то $\beta$ задана той же самой матрицей $A$.
\end{proof}

На это утверждение можно смотреть следующим образом. Давайте обсудим его в вещественном случае. Пусть у вас на пространстве $V$ задано две симметричные билинейные формы, причем одна из них положительно определена. Тогда существует базис, в котором обе формы задаются диагональными матрицами. В такой форме это утверждение возникает в дифференциальной геометрии для первой и второй квадратичной формы.

\begin{claim}
Пусть 
\begin{enumerate}
\item
$V$ -- вещественное пространство, $\beta\colon V\times V\to \mathbb R$ -- симметричная билинейная форма и пусть в базисе $e_1,\ldots,e_n$ форма имеет вид $\beta(x, y) = x^t B y$. 
\item
$V$ -- комплексное пространство, $\beta\colon V\times V\to \mathbb C$ -- эрмитова форма и пусть в базисе $e_1,\ldots,e_n$ форма имеет вид $\beta(x, y) = \bar x^t B y$. 
\end{enumerate}
Тогда характеристический многочлен $B$ раскладывается на линейные множители с вещественными коэффициентами и сигнатура $B$ определяется по знакам собственных значений матрицы $B$, а именно: $\#1$ совпадает с количеством положительных корней $\chi_B(t)$, $\#-1$ совпадает с количеством отрицательных корней $\chi_B(t)$, а $\#0$ совпадает с кратностью нуля в $\chi_B(t)$.
\end{claim}
\begin{proof}
Давайте введем в пространстве $V$ скалярное произведение такое, что $e_1,\ldots,e_n$ становится ортонормированным базисом. Тогда матрица $B$ задает линейный оператор $\phi\colon V \to V$ такой, что $\beta(v, u) = (v, \phi u)$. Так как $\beta$ симметричная (эрмитова), то $\phi^*$ самосопряжен. Мы можем найти новый ортонормированный базис $f_1,\ldots,f_n$, в котором $\phi$ диагонализуется $\diag(\lambda_1,\ldots,\lambda_n)$. Тогда числа на диагонали -- это спектр матрицы $B$. С другой стороны, $\beta$ в базисе $f_1,\ldots,f_n$ тоже задается матрицей $\diag(\lambda_1,\ldots,\lambda_n)$, а значит ее сигнатура определяется по количеству положительных, отрицательных и нулевых числе среди корней характеристического многочлена с учетом кратности.
\end{proof}

\subsection{Классификация линейных отображений}

Мы с вами уже занимались классификацией линейных отображений между двумя разными пространствами (утверждение~\ref{claim::HomClassification}). Выбирая базисы в двух пространствах независимо, мы можем добиться того, чтобы матрица превратилась в диагональную с единицами и нулями на диагонали. По сути, две прямоугольные матрицы задают одно и то же отображение между двумя разными пространствами тогда и только тогда, когда у них одинаковый ранг. Теперь у нас ситуация немного более жесткая. У нас теперь есть два пространства $V$ и $U$ и они либо вещественные, либо эрмитовы и задано линейное отображение $\phi\colon V\to U$. Но теперь в отличие от общего случая я хочу выбирать не произвольные базисы, а только ортонормированные. Таким образом у меня меньше свободы для модификации матрицы оператора. Оказывается, что даже в таком жестком случае, можно сделать матрицу оператора диагональной, то вот на диагонали будут стоять произвольные неотрицательные числа.

\begin{claim}\label{claim::HermEuclHomClass}
Пусть $V$ и $U$ -- евклидовы или эрмитовы пространства и $\phi\colon V\to U$ -- линейное отображение. Тогда
существует ортонормированный базис $e_1,\ldots,e_n$ в $V$, ортонормированный базис $f_1,\ldots,f_m$ в $U$ и последовательность вещественных чисел $\sigma_1\geqslant \sigma_2 \geqslant \ldots \geqslant \sigma_r > 0$ такие, что матрица $\phi$ имеет вид
\[
\phi(e_1,\ldots,e_n) = (f_1,\ldots,f_m) 
\begin{pmatrix}
{\sigma_1}&{}&{}&{}&{}&{}\\
{}&{\ddots}&{}&{}&{}&{}\\
{}&{}&{\sigma_r}&{}&{}&{}\\
{}&{}&{}&{\ddots}&{}&{}\\
{}&{}&{}&{}&{0}&{}\\
\end{pmatrix}
\]
При этом числа $\sigma_1,\ldots,\sigma_r$ определены однозначно и называются сингулярными значениями отображения $\phi$.
\end{claim}
\begin{proof}
Давайте рассмотрим билинейную форму $\beta(v, u) = (\phi(v), \phi(u))$ на пространстве $V$. Тогда это симметричная (эрмитова) неотрицательно определенная форма. Значит по утверждению~\ref{claim::BilinOrthoDiag} существует ортонормированный базис $e_1,\ldots,e_n$ в $V$, в котором она диагональна. Пусть матрица $\beta$ в этом базисе имеет вид $\diag(\lambda_1,\ldots,\lambda_r,0\ldots,0)$, причем $\lambda_1\geqslant \ldots \geqslant \lambda_r>0$. Положим $\sigma_1 = \sqrt{\lambda_1},\ldots,\sigma_r = \sqrt{\lambda_r}$. Теперь определим векторы $f_i = \frac{1}{\sigma_i}\phi(e_i)$ для $1\leqslant i\leqslant r$. Покажем, что система векторов $(f_1,\ldots,f_r)$ является ортономированной. Сначала проверим длины
\[
(f_i, f_i) = \left(\frac{1}{\sigma_i}\phi(e_i), \frac{1}{\sigma_i} \phi(e_i)\right) = \frac{1}{\sigma_i^2}\beta(e_i, e_i) = \frac{\lambda_i}{\sigma_i^2} = 1
\]
Теперь проверим ортогональность
\[
(f_i, f_j) = \left(\frac{1}{\sigma_i}\phi(e_i), \frac{1}{\sigma_j} \phi(e_j)\right) = \frac{1}{\sigma_i\sigma_j}\beta(e_i, e_j) = 0
\]
Теперь дополним векторы $f_1,\ldots,f_r\in U$ до ортонормированного базиса пространства $U$ и получим $f_1,\ldots,f_m$. Теперь методом пристального взгляда проверяем, что построенная пара базисов удовлетворяет требуемому условию:
\[
\phi(e_1,\ldots,e_n) = (f_1,\ldots,f_m) 
\begin{pmatrix}
{\sigma_1}&{}&{}&{}&{}&{}\\
{}&{\ddots}&{}&{}&{}&{}\\
{}&{}&{\sigma_r}&{}&{}&{}\\
{}&{}&{}&{\ddots}&{}&{}\\
{}&{}&{}&{}&{0}&{}\\
\end{pmatrix}
\]

Осталось показать, что числа $\sigma_i$ определены однозначно. Заметим, что $\beta(v, u) = (\phi v, \phi u) = (v, \phi^* \phi u)$. Тогда числа $\sigma_i$ определены как корни из спектра оператора $\phi^*\phi$.
\end{proof}

\subsection{SVD или сингулярное разложение}

Давайте переформулируем последнее утверждение в матричных терминах. Чтобы упростить изложение, я все сделаю для вещественного случая. Комплексный делается аналогично с той лишь разницей, что везде в формулах транспонированную матрицу $M^t$ надо менять на эрмитово сопряженную $M^* = \bar M^t$ при любой матрице $M$. В начале я переформулирую утверждение на матричном языке.

\begin{claim}
Пусть дана матрица $A\in \MatrixDim{m}{n}$. Тогда \begin{enumerate}
\item Существует $U\in \Matrix{m}$ такая, что $U^t U = E$.
\item Существует $V\in \Matrix{n}$ такая, что $V^t V = E$.
\item Существует последовательность вещественных чисел $\sigma_1\geqslant \sigma_2\geqslant \ldots\geqslant \sigma_r > 0$.
\end{enumerate}
такие, что $A = U \Sigma V^t$, где
\[
\Sigma =
\overbrace{
\begin{pmatrix}
{\sigma_1}&{}&{}&{}&{}&{}\\
{}&{\ddots}&{}&{}&{}&{}\\
{}&{}&{\sigma_r}&{}&{}&{}\\
{}&{}&{}&{\ddots}&{}&{}\\
{}&{}&{}&{}&{0}&{}\\
\end{pmatrix}
}^n
\left.
\vphantom{
\begin{pmatrix}
{\sigma_1}&{}&{}&{}&{}&{}\\
{}&{\ddots}&{}&{}&{}&{}\\
{}&{}&{\sigma_r}&{}&{}&{}\\
{}&{}&{}&{\ddots}&{}&{}\\
{}&{}&{}&{}&{0}&{}\\
\end{pmatrix}
}
\right\}{\scriptstyle m}
\]
При этом последовательность чисел $\sigma_1,\sigma_2,\ldots,\sigma_r$ определена однозначно.
\end{claim}

\begin{itemize}
\item Разложение матрицы $A$ в этом утверждении называется сингулярным разложением или SVD.

\item
Чтобы свести матричное утверждение к оператоному, надо рассмотреть пространства $\mathbb R^n$ и $\mathbb R^m$ со стандартным скалярным произведением и оператор $\phi\colon \mathbb R^n \to \mathbb R^m$ по правилу $x\mapsto Ax$. Тогда столбцы матрицы $U$ -- это базисные векторы $f_1,\ldots,f_m\in \mathbb R^m$, а столбцы $V$ -- это базисные векторы $e_1,\ldots,e_n$ из утверждения~\ref{claim::HermEuclHomClass}.

\item
Обратите внимание, что такое разложение не единственное. Например, если $A$ квадратная и равна единичной матрице, то подойдет любое разложение вида $A = U E U^t$, где $U$ -- произвольная ортогональная матрица. В данном случае эффект связан с тем, что все сингулярные значения одинаковые. Но даже, если сингулярные значения разные, вы можете домножать соответствующие столбцы $U$ и $V$ на минус единицу,\footnote{В комплексном случае домножать можно на пару сопряженных чисел по модулю равных единице.} например.
\[
A = (u_1|\ldots | u_m)\Sigma (v_1|\ldots|v_n)^t
\quad\text{тогда}\quad
A = (-u_1|\ldots | u_m)\Sigma (-v_1|\ldots|v_n)^t
\]
\item
Последний пример показывает, что не только разложение неоднозначно, но и что между столбцами $U$ и $V$ есть некоторое условие согласованности. Из-за этой неоднозначности в разложении, надо аккуратно искать все компоненты этого разложения. Если вы нашли какие-то части разложения, например матрицы $U$ и $\Sigma$, то матрицу $V$ надо искать не абы каким методом.
\end{itemize}

Заметим, что в SVD матрица $\Sigma$ имеет тот же размер, что и матрица $A$. Однако, ее правая часть полностью заполнена нулями. А значит, что умножение этой части на соответствующую часть матрица $V^t$ ни на что не повлияет. Предположим для определенности, что $n > m$, как на картинках. Тогда можем определить матрицу $\Sigma_0\in \Matrix{m}$ полученную из $\Sigma$ отрезанием последних $n - m$ нулевых столбцов. Так же заменим матрицу $V = (v_1|\ldots|v_n)$ на матрицу $V_0 = (v_1|\ldots|v_m)$. Тогда получим разложение вида 
\[
A = U \Sigma_0 V_0^t
\]
Это разложение называется усеченным сингулярным разложением и многие алгоритмы ищут именно его. Здесь квадратными являются $U$ и $\Sigma_0$, а столбцы $V_0$ образуют ортонормированную систему (не обязательно базис). Если бы было $m > n$, то разложение было бы вида
\[
A = U_0 \Sigma_0 V^t
\]
при этом квадратными были бы матрицы $\Sigma_0$ и $V$, а столбцы матрицы $U_0$ образуют ортонормированную систему (не обязательно базис).


Если пойти еще дальше и применить блочные формулы к сингулярному разложению, то можно получить разложение матрицы $A$ в сумму матриц ранга $1$, а именно
\[
A = \sigma_1 u_1 v_1^t + \ldots + \sigma_r u_r v_r^t
\]
Если задать на пространстве матриц $\MatrixDim{m}{n}$ скалярное произведение в виде $(A, B) = \tr(A^t B)$, то матрицы $u_iv_i^t$ будут ортонормированной системой в пространстве матриц, а написанное выше разложение -- это разложение матрицы $A$ по ортонормированному базису, состоящему из матриц ранга $1$. 

Последнее разложение используется для сжатия информации с потерей информации. Например, про матрицу $A$ можно думать как про картинку в шкале серого, где в ячейке матрицы задана интенсивность черного. В реальной жизни, числа $\sigma_1\geqslant \ldots \geqslant \sigma_r$ убывают очень быстро и последние значения ничтожно малы. Если вы откините последнее слагаемое $\sigma_ru_rv_r^t$, то вы измените исходную матрицу $A$. Однако, $u_r$ и $v_r$ -- векторы нормы $1$, а значит их координаты по модулю не больше единицы, а значит у матрицы $\sigma_r u_rv_r^t$ координаты не больше, чем $\sigma_r$ по модулю. Значит, если $\sigma_r$  мало, то выкидывание последнего слагаемого меняет каждый коэффициент матрицы $A$ на очень малую величину, незаметную для глаза. Таким образом, вместо того, чтобы хранить матрицу $A$ целиком (для этого нужно $mn$ ячеек памяти), мы можем отрезать в каком-нибудь месте сумму в сингулярном разложении и хранить
\[
A' = \sigma_1 u_1 v_1^t + \ldots + \sigma_k u_k v_k^t
\]
Здесь нам понадобится $k$ ячеек памяти под $\sigma_i$, $km$ ячеек памяти под векторы $u_i$ и $kn$ ячеек памяти под векторы $v_i$. Итого будет $k(1 + n + m)$ ячеек памяти. При этом параметр $k$ контролирует степень сжатия картинки.

\subsection{Ортопроекторы}

В этом разделе я хочу обсудить некоторые технические факты, которые мне понадобятся для задачи о низкоранговом приближении. Давайте напомню, что такое проекторы и ортопроекторы. Пусть $V$ -- векторное пространство, $U, W\subseteq V$ -- его подпространства и $V = U \oplus W$. Тогда любой вектор $ v$ однозначно раскладывается в сумму $v = u + w$, где $u\in U$ и $w\in W$. Тогда можно определить отображение $P\colon V\to V$ по правилу $v\mapsto u$. Как легко видеть $P$ является линейным оператором. Он называется проектором на $U$ вдоль $W$. Заметим, что $P$ действует тождественно на $U$ и нулем на $W$. Кроме того, $U = \Im P$, а $W = \ker P$. Или в терминах собственных подпространств $U$ -- это $V_1$ собственное подпространство для $1$, а $W = V_0$ -- собственное подпространство для $0$.

\begin{claim}
Пусть $V$ -- векторное пространство и $P\colon V\to V$ -- некоторый линейный оператор. Тогда $P$ является проектором тогда и только тогда, когда $P^2 = P$.
\end{claim}
\begin{proof}
Действительно, если $P$ проектор, то по определению он удовлетворяет нужному свойству. Обратно, если $P^2 = P$, то многочлен $x^2 - x$ является зануляющим для $P$, а значит минимальный многочлен не имеет кратных корней. По утверждению~\ref{claim::GenRootDec} это означает, что $P$ диагонализуется. Кроме того спектр $P$ лежит среди корней многочлена $x^2 - x$. То есть собственными значениями могут быть только $1$ и $0$. Диагонализуемость означает, что $V = V_1\oplus V_0$. Но тогда по определению $P$ действует тождественно на $V_1$ и нулем на $V_0$, что и требовалось показать.
\end{proof}

Пусть теперь $V$ -- евклидово или эрмитово пространство и $U\subseteq V$ -- некоторое подпространство. Тогда $V = U\oplus U^\bot$. В этом случае проектор на $U$ вдоль $U^\bot$ называется ортопроектором на $U$.

\begin{claim}
Пусть $V$ -- евклидово или эрмитово пространство и $P\colon V\to V$ -- некоторый оператор. Тогда $P$ является ортопроектором тогда и только тогда, когда $P^2 = P$ и $P^* = P$.
\end{claim}
\begin{proof}
Мы уже знаем, что $P$ проектор тогда и только тогда, когда $P^2 = P$. Надо показать, что при этом условии ядро и образ проектора ортогональны тогда и только тогда, когда $P$ самосопряжен.


Предположим, что $P$ ортопроектор, то есть ядро ортогонально образу. Выберем $e_1,\ldots,e_k$ -- ортонормированный базис образа и $e_{k+1}, \ldots,e_n$ -- ортонормированный базис ядра. Тогда в силу ортогональности ядра и образа, $e_1,\ldots,e_n$ будет ортонормированным базисом $V$ и в нем $P$ задан матрицей $A=\left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right)$. То есть $A^t = A$ в вещественном случае или $\bar A^t  = A$ в комплексном. Последнее означает, что $P$ самосопряжен.

Обратно, пусть $P^* = P$. Надо показать, что ядро и образ ортогональны. Пусть $u = Pv\in \Im P$ и $w \in \ker P$, тогда
\[
(u, w) = (Pv, w) = (v, P^*w) = (v, Pw) = (v, 0) = 0
\]
\end{proof}

\begin{claim}
Пусть $V$ -- евклидово или эрмитово пространство, $P\colon V\to V$ -- ортопроектор на некоторое подпространство $U$ и $e_1,\ldots,e_n$ -- ортонормированный базис пространства $V$. Тогда
\[
\sum_{i=1}^n |Pe_i|^2 = \dim U
\]
\end{claim}
\begin{proof}
Давайте посчитаем след оператора $P$ двумя разными способами. Если мы выберем базис $e_1,\ldots,e_k$ в пространстве $U$ и $e_{k+1}, \ldots,e_n$ базис в $U^\bot$, то оператор $P$ в нем задается матрицей $\left(\begin{smallmatrix}{E}&{0}\\{0}&{0}\end{smallmatrix}\right)$. То есть $\tr P = \dim U$.

С другой стороны, давайте посчитаем левую часть выражения
\[
\sum_{i=1}^n |Pe_i|^2 = \sum_{i=1}^n (Pe_i, Pe_i) = \sum_{i=1}^n (e_i, P^*Pe_i) = \sum_{i=1}^n (e_i, P^2e_i) = \sum_{i=1}^n (e_i, Pe_i)
\]
Так как базис $e_1,\ldots,e_n$ ортонормированный, то скалярное произведение стандартное. Если $P(e_1,\ldots,e_n) = (e_1,\ldots,e_n)A$, то $(e_i, Pe_i) = a_{ii}$. Таким образом $ \sum_{i=1}^n (e_i, Pe_i) = \sum_{i=1}^na_{ii} = \tr P$.
\end{proof}

\subsection{Задача о низкоранговом приближении}

Пусть теперь $A\in \MatrixDim{m}{n}$ или $A\in \operatorname{M}_{m\,n}(\mathbb C)$. Зададим на пространствах матриц скалярное произведение. В вещественном случае по формуле $(A, B) = \tr(A^t B)$, а в комплексном $(A, B) = \tr(A^*B)$. Длина относительно заданного скалярного произведения называется нормой фробениуса и выражается следующим образом (в вещественном или комплексном случае соответственно):
\[
\|A\|_F = \sqrt{\sum_{ij}a_{ij}^2}
\quad\text{или}\quad
\|A\|_F = \sqrt{\sum_{ij}|a_{ij}|^2}
\]
Если матрица $A$ имеет вид $A = (A_1|\ldots|A_n)$, тогда $\|A\|_F^2 = \sum_{i=1}^n |A_i|^2$, где $|A_i|$ -- длина относительно стандартного скалярного произведения для столбца $A_i$.

Теперь наша задача -- заменить матрицу $A$ на матрицу $B$ ранга не выше $k$, причем мы хотим выбрать $B$ ближайшей в смысле нормы фробениуса. То есть мы зафиксируем матрицу $A$ и число $k$ и будем решать задачу
\[
\left\{
\begin{aligned}
&\|A - B\|_F \to \min_B\\
&\rk B \leqslant k
\end{aligned}
\right.
\]
Важно понимать, что множество матриц ранга не выше $k$ не образуют линейное подпространство в пространстве матриц. А значит, тут не получится решить эту задачу просто применением ортопроекторов. Кроме того, задача может иметь не единственное решение, в некоторых ситуациях ближайших матриц может оказаться бесконечное число.

Обратите внимание, что если $k \geqslant \rk A$, то ответом будет сама матрица $A$. А если $k < \rk A$, то оказывается, что SVD дает нужный ответ к данной задаче. Нужно найти для матрицы $A$ сингулярное разложение. После чего, выбрать в качестве нужной матрицы матрицу
\[
B_k = \sigma_1 u_1 v_1^t + \ldots + \sigma_k u_k v_k^t
\]
Доказательству этого факта будет посвящен этот раздел.