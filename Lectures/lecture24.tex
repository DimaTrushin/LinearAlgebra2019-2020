\ProvidesFile{lecture24.tex}[Лекция 24]

\subsection{Двойственность для линейных отображений и операторов}

В утверждении ниже, мы предполагаем, что все ортогональные дополнения берутся относительно естественной билинейной формы, то есть $\langle, \rangle\colon V^*\times V\to F$, где $(\xi, v)\mapsto \langle \xi, v\rangle := \xi(v)$. В данном случае, я не буду различать левые и правые ортогональные дополнения, так как понятно, в каком пространстве находятся соответствующие подпространства. В частности, если $W\subseteq V$, то $W^\bot\subseteq V^*$ и наоборот, если $W\subseteq V^*$, то $W^\bot \subseteq V$.

\begin{claim}[Альтернатива Фредгольма]\label{claim::Fredholm}
Пусть $\varphi\colon V\to U$ -- некоторое линейное отображение и $\varphi^*\colon U^*\to V^*$ -- сопряженное к нему. Тогда
\begin{enumerate}
\item $(\Im \varphi)^\bot = \ker \varphi^*$.
\item $(\ker \varphi)^\bot = \Im \varphi^*$.
\end{enumerate}
\end{claim}
\begin{proof}
В начале докажем, что (1) влечет (2). По утверждению~\ref{claim::DualitySpaces} пункты~(2) и~(3) равенство $(\ker \varphi)^\bot = \Im \varphi^*$ эквивалентно равенству $\ker \varphi = (\Im \varphi^*)^\bot$. Что эквивалентно $(\Im \varphi^*)^\bot = \ker(\varphi^*)^*$ (утверждение~\ref{claim::CanonicalIsomorphism}). Следовательно (2) равносильно (1), примененному к отображению $\varphi^*\colon U^*\to V^*$.

(1) Следующая цепочка равенств проводит доказательство:
\[
\ker\varphi^* =\{\xi \in U^*\mid \varphi^*(\xi) = 0\} = \{\xi \in U^*\mid \xi \varphi = 0\} = \{\xi\in U^*\mid \xi(\Im \varphi) = 0\} = \{\xi\in U^*\mid \langle \xi, \Im\varphi\rangle = 0\} = (\Im \varphi)^\bot
\]
\end{proof}

\paragraph{Замечание}
Попробуйте расписать явно условие $(\ker \varphi)^\bot = \Im \varphi^*$ и доказать его в лоб без применения двойственности. Это очень полезное упражнение.

В случае, когда $\varphi\colon V\to V$ является оператором, то у него намного больше характеристик, чем просто ядро и образ. Следующее утверждение подытоживает все знания об общих характеристиках воедино.

\begin{claim}
Пусть $\varphi\colon V\to V$ -- некоторый линейный оператор над полем $F$. Тогда
\begin{enumerate}
\item $\tr \varphi = \tr \varphi^*$.

\item $\det \varphi = \det \varphi^*$.

\item $\chi_\varphi = \chi_{\varphi^*}$.

\item $f_{\text{min},\,\varphi} = f_{\text{min},\,\varphi^*}$.

\item $\spec_F(\varphi) = \spec_F(\varphi^*)$.

\item $\spec_F^I(\varphi) = \spec_F^I(\varphi^*)$.

\item если $U\subseteq V$ -- $\varphi$-инвариантное, то $U^\bot\subseteq V^*$ -- $\varphi^*$-инвариантное.
\end{enumerate}
\end{claim}
\begin{proof}
Все утверждения кроме последнего следуют из утверждения~\ref{claim::DualHomMatrix}, которое гласит, что при правильном выборе базисов в $V$ и $V^*$ матрицы $\varphi$ и $\varphi^*$ отличаются транспонированием.

(7) Нам дано $\varphi(U)\subseteq U$, а надо показать, что $\varphi^*(U^\bot)\subseteq U^\bot$. Пусть $\xi\in U^\bot$, то есть $\xi(U) = 0$, надо проверить, что $\varphi^*(\xi)(U) = 0$. То есть надо проверить, что $(\xi \varphi)(U) = 0$. Но $(\xi \varphi) (U) = \xi(\varphi(U))\subseteq \xi(U) = 0$, что и требовалось.
\end{proof}

\paragraph{Замечания}
\begin{itemize}
\item Таким образом изучение оператора $\varphi$ это тоже самое, что изучение оператора $\varphi^*$, если при этом <<перевернуть>> все пространства. То есть любой вопрос про $\varphi^*$ можно переформулировать в терминах $\varphi$, заменив размерности подпространств в формулировках на $n$ минус размерность (здесь $n$ -- размерность объемлющего пространства $V$).

\item На самом деле для $\varphi$ и $\varphi^*$ совпадают жордановы нормальные формы. Действительно, если вы транспонируете матрицу в жордановой нормальной форме, то результирующая матрица будет иметь ту же самую жорданову нормальную форму.

\item Хорошее упражнение для ума: пусть $e_1,\ldots,e_n$ -- жорданов базис для $\varphi$, а $e^1,\ldots,e^n$ -- двойственный к нему базис. Как из $e^1,\ldots,e^n$ получить жорданов базис для $\varphi^*$?
\end{itemize}

\paragraph{Примеры}
\begin{enumerate}
\item Пусть $\varphi\colon V\to V$ такой, что характеристический многочлен $\varphi$ раскладывается на линейные множители. А это означает, что $V$ раскладывается в прямую сумму корневых, то есть $V = V^{\lambda_1}\oplus \ldots \oplus V^{\lambda_r}$ (утверждение~\ref{claim::RootSpaceDec}). Так как характеристический многочлен у $\varphi^*$ такой же, то $V^* = (V^*)^{\lambda_1}\oplus \ldots \oplus (V^*)^{\lambda_r}$. Давайте покажем, что $(V^{\lambda_1})^\bot = (V^*)^{\lambda_2}\oplus \ldots \oplus (V^*)^{\lambda_r}$.

Самый простой способ сделать это такой. Рассмотрим многочлен $p(t) = (t-\lambda_1)^{k_1}$, где $k_1$ -- кратность $\lambda_1$ в $\chi_\varphi$. Тогда $V^{\lambda_1} = \ker p(\varphi)$ (это, например, следует из утверждения~\ref{claim::RootMultGeom}, однако, можно просто взять достаточно большое $k_1$ и можно обойтись леммой о стабилизации -- утверждение~\ref{claim::StabilityLemma}). По утверждению~\ref{claim::Fredholm} о двойственности для линейных отображений, мы получаем, что $(\ker p(\varphi))^\bot = \Im (p(\varphi))^* = \Im p(\varphi^*)$. Последнее равенство проверяется в лоб:
\[
p(\varphi)^* =  \Bigl(\sum_ka_k\varphi^k\Bigr)^* = \sum_ka_k \left(\varphi^k\right)^* = \sum_k a_k \left(\varphi^*\right)^k = p(\varphi^*)
\]
По утверждению~\ref{claim::IdealRootDec} для оператора $\varphi^*$ последний образ как раз и равен сумме оставшихся корневых\footnote{Если не понятно, на что я тут ссылаюсь, то загляните в доказательство утверждения~\ref{claim::GenRootDec} пункт~(2), это должно снять все вопросы.}.

\item Пусть $\varphi\colon V\to V$ -- линейный оператор над полем $\mathbb C$. Тогда мы знаем, что обязательно найдется ненулевой собственный вектор $v\in V_\lambda$ для некоторого $\lambda\in \mathbb C$. Последнее равносильно тому, что найдется инвариантное одномерное подпространство $\langle v \rangle$. Давайте покажем, как с помощью двойственности автоматически найти инвариантное $n - 1$ мерное подпространство, где $n = \dim V$. Пусть $U\subseteq V^*$ -- инвариантное одномерное для $\varphi^*$. Такое существует, потому что у $\varphi^*$ есть собственный вектор (мы над полем $\mathbb C$). В этом случае $U^\bot\subseteq V$ будет $n-1$ мерным и инвариантным для $\varphi$ по пункту~(7) предыдущего утверждения.
\end{enumerate}

\subsection{Структура векторного пространства на $\Bil(V,U)$}

До сих пор мы смотрели на $\Bil(V, U)$ как на множество билинейных форм, такой мешок, в котором аморфно лежат все наши замечательные симпатичные формочки, одна лучше другой. На самом деле $\Bil(V, U)$ само является векторным пространством. По-простому, это означает, что на $\Bil(V, U)$ есть хорошие операции сложения и умножения на константу. 

\begin{definition}
Пусть $\beta_1,\beta_2\colon V\times U \to F$ -- две билинейные формы. Мы хотим определить форму $\beta_1 + \beta_2$. Это значит, что нам надо определить отображение $(\beta_1 + \beta_2)\colon V\times U \to F$. Определим его по правилу
\[
(\beta_1 + \beta_2)(v, u) := \beta_1(v,u) + \beta_2(v,u)
\]
Если $\beta\colon V\times U \to F$ -- билинейная форма и $\lambda\in F$, тогда форму $(\lambda \beta)\colon V\times U \to F$ определим по правилу
\[
(\lambda\beta)(v, u) := \lambda \beta(v, u)
\]
\end{definition}

\paragraph{Замечания}
\begin{itemize}
\item 
В качестве упражнения я предлагаю проверить, что $\beta_1 + \beta_2$ и $\lambda\beta$ -- это не просто отображения из $V\times U$ в $F$, а билинейные формы, то есть удовлетворяют условиям определения~\ref{def::BilinearForms}. Это объясняет, что определенные выше операции корректны, то есть их результат -- это тоже билинейная форма.

\item
В качестве другого упражнения я предлагаю проверить, что множество $\Bil(V, U)$ является векторным пространством, то есть надо проверить аксиомы из определения~\ref{def::VectorSpace}.

\item Чтобы немного вывернуть мозги наизнанку, давайте вспомним, что билинейные формы имеют операторную запись, то есть вместо $\beta\colon V\times U\to F$ мы будем писать $\cdot_\beta\colon V\times U \to F$, при это $\beta(v, u) = v \cdot_\beta u$. То есть билинейные формы -- это операции умножения векторов, которые в результате возвращают число. Так вот, мы только что определили как складывать и умножать на числа операции умножения так, что они остаются операциями умножения! Определения выше можно переписать так
\begin{align*}
v (\cdot_{\beta_1} + \cdot_{\beta_2}) u &= v \cdot_{\beta_1} u + v \cdot_{\beta_2} u\\
v(\lambda \cdot_\beta) u &= \lambda (v \cdot_\beta u)
\end{align*}
Неправда ли выносит мозг? Это лишний раз говорит о том, что в математике очень важно правильно думать об объекте. Сложение билинейных форм не представляется нам чем-то особенным, вот умение складывать операции умножения кажется диким. Психологические барьеры надо уметь перепрыгивать.
\end{itemize}

Теперь вспомним, что фиксировав базисы в пространствах $V$ и $U$, каждая билинейная форма превращается в матрицу (утверждение~\ref{claim::BilinearMatrices}). Так вот, заметим, что это превращение является измомрфизмом между векторными пространствами. Для полноты картины я все же сформулирую сам результат.

\begin{claim}%\label{claim::BilinearIsomMatrices}
Пусть $\beta\colon V\times U\to F$ -- некоторая билинейная форма,  $e = (e_1,\ldots,e_n)$ -- базис пространства $V$ и $f=(f_1,\ldots,f_m)$ -- базис пространства $U$. Тогда отображение $\operatorname{Bil}(V,U)\to \operatorname{M}_{n\,m}(F)$ по правилу $\beta\mapsto B_\beta$ является изоморфизмом.
\end{claim}

\subsection{Классификационная задача для $\Bil(V,U)$}

\begin{claim}
Пусть $V$ и $U$ -- векторные пространства над полем $F$ размерностей $n$ и $m$, соответственно, и пусть $A,B\in \operatorname{M}_{n\,m}(F)$ -- произвольные матрицы. Тогда эквивалентны следующие утверждения:
\begin{enumerate}
\item Матрицы $A$ и $B$ задают одну и ту же билинейную форму на $V$ и $U$ в разных базисах, т.е. существует билинейная форма $\beta\colon V\times U\to F$, два базиса в $V$: $e=(e_1,\ldots,e_n)$ и $e'=(e_1',\ldots,e_n')$ и два базиса в $U$: $f=(f_1,\ldots,f_m)$ и $f'=(f_1',\ldots,f_m')$ такие, что $A$ является матрицей $\beta$ в базисах $e$ и $f$, а $B$ является матрицей $\beta$ в базисах $e'$ и $f'$.

\item $\rk A = \rk B$.
\end{enumerate}
\end{claim}
\begin{proof}
Из (1) в (2) мы уже знаем, это корректность ранга билинейной формы.

Из (2) в (1). Так как ранги матриц $A$ и $B$ одинаковые, мы можем найти такие обратимые матрицы $C,R \in \operatorname{M}_{n}(F)$ и $D, P\in \operatorname{M}_{m}(F)$, что
\[
A = C
\begin{pmatrix}
{E}&{0}\\
{0}&{0}
\end{pmatrix}
D,
\quad
B = R
\begin{pmatrix}
{E}&{0}\\
{0}&{0}
\end{pmatrix}
P
\]
А значит $B = RC^{-1}AD^{-1}P$, то есть $B = S^t A T$, где $S = (RC^{-1})^t$ и $T = D^{-1}P$. Теперь нам надо найти билинейную форму  и две пары базисов. Возьмем два произвольных базиса $e=(e_1,\ldots,e_n)$ в $V$ и $f=(f_1,\ldots,f_m)$ в $U$ и положим $\beta\colon V\times U \to F$ по правилу $\beta(v, u) = x^t A y$, где $v = ex$ и $x\in F^n$, $u = f y$ и $y\in F^m$. После положим $e' = e S$ и $f' = fT$. Так как $S$ и $T$ невырожденные матрицы, то $e'$ будет базисом $V$, а $f'$ -- базисом $U$. Тогда в новой паре базисов матрица нашей билинейной формы будет $S^t A T$, что совпадает с $B$ по построению.
\end{proof}

Таким образом, как и в случае линейного отображения, две матрицы задают одну и ту же билинейную форму тогда и только тогда, когда их ранги совпадают. Следующая наша задача разобраться со случаем аналогичным случаю оператора, а именно: билинейная форма определена на одном пространстве.

\newpage
\section{Билинейные формы на одном пространстве $\Bil(V)$}

В случае, когда линейное отображение определено на одном пространстве (линейный оператор), у нас в запасе намного больше конструкций и характеристик, чем в случае общего линейного отображения. Аналогичная ситуация обстоит и с билинейными формами. В случае, когда билинейная форма живет на одном пространстве у нас на много больше характеристик и поведение ее изучать несколько сложнее. Ниже я буду рассказывать о билинейных формах на одном пространстве. Окажется, что от части ситуация с билинейными формами технически сильно проще, чем случай линейных операторов.

\subsection{Разложение в прямую сумму}

Пусть $V$ -- векторное пространство над полем $F$. Тогда будем обозначать через $\SBil(V)$ множество симметричных билинейных форм на $V$, а через $\ABil(V)$ множество кососимметричных билинейных форм. Напомним, что если $2 = 0$ в поле $F$, то $\ABil(V)\subseteq \SBil(V)$ (утверждение~\ref{claim::BilSymAntiSym}). Этот пример объясняет ограничение случаем $2 \neq 0$ в следующем утверждении.

\begin{claim}\label{claim::BilDirectSA}
Пусть $V$ -- векторное пространство над полем $F$ таким, что $2 \neq 0$. Тогда любая билинейная форма $\beta\colon V\times V\to F$ единственным образом раскладывается в сумму симметрической и кососимметрической. На языке векторных пространств это означает, что $\Bil(V) = \SBil(V) \oplus \ABil(V)$.
\end{claim}
\begin{proof}
Я лишь предъявлю желаемое разложение 
\[
\beta(v,u) = \frac{\beta(v,u) + \beta(u, v)}{2} + \frac{\beta(v,u) - \beta(u,v)}{2}
\]
Все детали остаются на совести читателя.
\end{proof}

В дальнейшем наше основное внимание будет уделено симметричным билинейным формам.